{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef8f9b5b-74bf-481b-9686-9936b310a263",
   "metadata": {},
   "source": [
    "Chapter 15\n",
    "\n",
    "# 六条PCA路线\n",
    "Book_7《机器学习》 | 鸢尾花书：从加减乘除到机器学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d382d-d983-46e1-a01a-9778c1a41863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e953728-6860-4d51-a9df-debf30bc0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% self-defined PCA function\n",
    "\n",
    "def PCA(X, method = 'demean'):\n",
    "    \n",
    "    n = len(X) # number of sample data\n",
    "    \n",
    "    if method == 'original':\n",
    "        XX = X.dropna()\n",
    "        GG = (XX.T @ XX)/(n - 1) # devided by (n-1) to make it comparable\n",
    "        variance_V, V = np.linalg.eig(GG)\n",
    "        \n",
    "    elif method == 'demean':\n",
    "        XX = (X - X.mean()).dropna()\n",
    "        GG = XX.T @ XX/(n - 1)\n",
    "        variance_V, V = np.linalg.eig(GG)\n",
    "        \n",
    "    elif method == 'normalize':\n",
    "        XX = (X - X.mean())/X.std().dropna()\n",
    "        GG = XX.T @ XX/(n - 1)\n",
    "        variance_V, V = np.linalg.eig(GG)\n",
    "        \n",
    "    else:\n",
    "            print('Method does not exist. Choose from original, demean, and normalize')\n",
    "            \n",
    "    original_variance = np.diag(GG)\n",
    "   \n",
    "    explained_variance_ratio = variance_V / np.sum(variance_V)\n",
    "    return [explained_variance_ratio, variance_V, V, original_variance, GG, XX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ca823-3543-4e22-8bee-c8aedc63a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% visualization tools\n",
    "\n",
    "# ==================================================\n",
    "# Define a function for plotting vector on a plane\n",
    "# ==================================================\n",
    "\n",
    "def draw_vector(v,RBG,label):\n",
    "    array = np.array([[0,0,v[0],v[1]]])\n",
    "    X,Y,U,V = zip(*array)\n",
    "    plt.quiver(X,Y,U,V,\n",
    "              angles='xy', \n",
    "              scale_units='xy',\n",
    "              scale = 1,\n",
    "              color = RBG,\n",
    "              label = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177425b-c2a3-43bd-bbce-8d359a85fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Define a function for plotting EVD\n",
    "# ==================================================\n",
    "\n",
    "def heatmap_EVD(GG,Lambdas,V):\n",
    "    \n",
    "\n",
    "    fig,axs = plt.subplots(1,7,figsize = (18,5))\n",
    "    \n",
    "    plt.sca(axs[0])\n",
    "    ax = sns.heatmap(GG, cmap = 'RdYlBu_r',\n",
    "                    # vmax = D_max, vmin = D_min,\n",
    "                    cbar_kws = {'orientation':'horizontal'},\n",
    "                    yticklabels=False,\n",
    "                    square = 'equal')\n",
    "    plt.title('$A$')\n",
    "    \n",
    "    plt.sca(axs[1])\n",
    "    plt.title('=')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.sca(axs[2])\n",
    "    ax = sns.heatmap(V, cmap = 'RdYlBu_r',\n",
    "                    vmax = 1, vmin = -1,\n",
    "                    cbar_kws = {'orientation':'horizontal'},\n",
    "                    yticklabels=False,\n",
    "                    square = 'equal')\n",
    "    plt.title('$V$')\n",
    "    \n",
    "    plt.sca(axs[3])\n",
    "    plt.title('@')\n",
    "    plt.axis('off')    \n",
    "    \n",
    "    plt.sca(axs[4])\n",
    "    ax = sns.heatmap(np.diag(Lambdas), cmap = 'RdYlBu_r',\n",
    "                    # vmax = D_max, vmin = D_min,\n",
    "                    cbar_kws = {'orientation':'horizontal'},\n",
    "                    yticklabels=False,\n",
    "                    square = 'equal')\n",
    "    plt.title('$\\Lambda$')\n",
    "\n",
    "    plt.sca(axs[5])\n",
    "    plt.title('@')\n",
    "    plt.axis('off')    \n",
    "    \n",
    "    plt.sca(axs[6])\n",
    "    ax = sns.heatmap(V.T, cmap = 'RdYlBu_r',\n",
    "                    vmax = 1, vmin = -1,\n",
    "                    cbar_kws = {'orientation':'horizontal'},\n",
    "                    yticklabels=False,\n",
    "                    square = 'equal')\n",
    "    plt.title('$V^T$')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec4645-cf3b-4c80-bfe2-38fd67ce7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# ==================================================\n",
    "# Define a function for plotting GG and Lambda\n",
    "# ==================================================\n",
    "\n",
    "def heatmap_GG(GG, variance_V):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,6))\n",
    "    \n",
    "    \n",
    "    x_axis_labels = ['$X_' + str(index + 1) + '$' for index in range(len(X.columns))]\n",
    "    y_axis_labels = X.columns\n",
    "    sns.heatmap(GG, \n",
    "                ax = ax[0], \n",
    "                xticklabels=x_axis_labels, \n",
    "                yticklabels=y_axis_labels,\n",
    "                vmin = np.minimum(GG, variance_V).min().min(),\n",
    "                vmax = np.maximum(GG, variance_V).max().max(),\n",
    "                annot = True,\n",
    "                square = 'equal',\n",
    "                cmap = 'RdYlBu_r', linewidths = 0.1,\n",
    "                cbar=False, fmt='.3f')\n",
    "    ax[0].set_title('Orginal')\n",
    "    ax[0].tick_params(axis='y', rotation=90)\n",
    "\n",
    "    x_axis_labels = ['$PC_' + str(index + 1) + '$' for index in range(len(X.columns))]\n",
    "    \n",
    "    sns.heatmap(np.diag(variance_V), \n",
    "                ax = ax[1], \n",
    "                xticklabels=x_axis_labels, \n",
    "                yticklabels=x_axis_labels,\n",
    "                vmin = np.minimum(GG, variance_V).min().min(),\n",
    "                vmax = np.maximum(GG, variance_V).max().max(),\n",
    "                annot = True,\n",
    "                square = 'equal',\n",
    "                cmap = 'RdYlBu_r', linewidths = 0.1,\n",
    "                cbar=False, fmt='.3f')\n",
    "    ax[1].set_title('Lambdas')\n",
    "    ax[1].tick_params(axis='y', rotation=90) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ad0f2-a660-46de-8999-f333f5ba8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Define a function for plotting heatmap of matrix V\n",
    "# ==================================================\n",
    "\n",
    "def heatmap_V(V,X,title):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    \n",
    "    x_axis_labels = ['$PC_' + str(index + 1) + '$' for index in range(len(X.columns))]\n",
    "    y_axis_labels = X.columns\n",
    "    sns.heatmap(V, \n",
    "                ax = ax, \n",
    "                xticklabels=x_axis_labels, \n",
    "                yticklabels=y_axis_labels,\n",
    "                vmin = -1,\n",
    "                vmax = 1,\n",
    "                annot = True,\n",
    "                square = 'equal',\n",
    "                cmap = 'RdYlBu_r', linewidths = 0.1,\n",
    "                cbar=False)\n",
    "    ax.set_title(title)\n",
    "    plt.yticks(rotation=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe25bb-2689-4fdf-a109-01ee1564e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Define a function of generating biplot \n",
    "# ==================================================\n",
    "def biplot(V,X,title):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    \n",
    "    y_axis_labels = X.columns\n",
    "    \n",
    "    RBGs = ['r','b','g','orange']\n",
    "    \n",
    "    for i, (RBG_i, label) in enumerate(zip(RBGs, y_axis_labels)):\n",
    "        \n",
    "        v = V[i,[0,1]]\n",
    "        \n",
    "        draw_vector(v,RBG_i,label)\n",
    "    \n",
    "    circ = plt.Circle((0, 0), radius=1, edgecolor='k', linestyle = '--', facecolor='None')\n",
    "    ax.add_patch(circ)\n",
    "    plt.xlabel('$PC_1$, $v_1$')\n",
    "    plt.ylabel('$PC_2$, $v_2$')\n",
    "    plt.legend()\n",
    "    plt.xticks(np.linspace(-1,1,5))\n",
    "    plt.yticks(np.linspace(-1,1,5))\n",
    "    ax.set_xlim(-1,1)\n",
    "    ax.set_ylim(-1,1)\n",
    "    ax.grid(color = [0.6,0.6,0.6])\n",
    "    ax.set_title(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78375d-6ea3-489a-95d9-1764f1e997e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Define a function of generating 6 biplots\n",
    "# lower triangle arrangment\n",
    "# ==================================================\n",
    "\n",
    "def six_biplots(V,X):\n",
    "    \n",
    "    fig = plt.figure(figsize=(18,18))\n",
    "    \n",
    "    y_axis_labels = X.columns\n",
    "    \n",
    "    RBGs = ['r','b','g','orange']\n",
    "    PC_combos = [[0,1],[0,2],[1,2],[0,3],[1,3],[2,3]]\n",
    "    \n",
    "    for fig_i,PC_combo_i in zip([1, 4, 5, 7, 8, 9], PC_combos): # lower triangle\n",
    "    \n",
    "        plt.subplot(3,3,fig_i)\n",
    "    \n",
    "        for i, (RBG_i, label) in enumerate(zip(RBGs, y_axis_labels)):\n",
    "            \n",
    "            print(PC_combo_i)\n",
    "            v = V[i,PC_combo_i]\n",
    "            \n",
    "            draw_vector(v,RBG_i,label)\n",
    "            \n",
    "        plt.legend(loc = 'best')\n",
    "        plt.xticks(np.linspace(-1,1,5))\n",
    "        plt.yticks(np.linspace(-1,1,5))\n",
    "        plt.xlim(-1,1)\n",
    "        plt.ylim(-1,1)\n",
    "        plt.gca().set_box_aspect(1)\n",
    "        # ax.set_box_aspect(1)\n",
    "        plt.grid(color = [0.6,0.6,0.6])\n",
    "    \n",
    "    allaxes = fig.get_axes()\n",
    "    \n",
    "    for ax in allaxes:\n",
    "        \n",
    "        circ = plt.Circle((0, 0), radius=1, edgecolor='k', linestyle = '--', facecolor='None')\n",
    "        ax.add_patch(circ)\n",
    "\n",
    "    \n",
    "    allaxes[3].set_xlabel('$PC_1$')\n",
    "    allaxes[4].set_xlabel('$PC_2$')\n",
    "    allaxes[5].set_xlabel('$PC_3$')\n",
    "    \n",
    "    allaxes[0].set_ylabel('$PC_2$')\n",
    "    allaxes[1].set_ylabel('$PC_3$')\n",
    "    allaxes[3].set_ylabel('$PC_4$')\n",
    "\n",
    "# ==================================================\n",
    "# Define a function of plotting pie and bar chats of \n",
    "# diagonal elements (varainces, lambdas, etc)\n",
    "# =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ece15-be63-4578-96c7-bab495e5b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_and_barh(variance_array,bar_max,PCA = True):\n",
    "    \n",
    "    if PCA:\n",
    "        \n",
    "        labels = ['$PC_' + str(index) + '$' for index in [1,2,3,4]]\n",
    "        \n",
    "    else:\n",
    "        labels = ['$X_' + str(index) + '$' for index in [1,2,3,4]]\n",
    "        \n",
    "    var_X2_drill_down_df = pd.DataFrame({'var':variance_array}, index = labels)\n",
    "    \n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(18,9))\n",
    "    \n",
    "    # var_X2_drill_down_df.sort_values('var',inplace=True)\n",
    "    var_X2_drill_down_df.plot.pie(y = 'var', autopct='%1.1f%%',wedgeprops={'alpha':0.5},\n",
    "                                  legend = False, cmap='rainbow_r', ax = ax1)\n",
    "    \n",
    "    var_X2_drill_down_df.plot.barh(y = 'var', ax = ax2)\n",
    "    ax2.set_xlim(0,bar_max)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4d3ad-e33b-48dc-bf05-3b1e46b43113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Define a function of generating Scree plot \n",
    "# ==================================================\n",
    "\n",
    "def Scree(explained_variance_ratio,variance_V):\n",
    "    # double y plot\n",
    "    \n",
    "    PC_range = np.arange(len(explained_variance_ratio)) + 1\n",
    "    labels = ['$PC_' + str(index) + '$' for index in PC_range]\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(9,5))\n",
    "    \n",
    "    ax1.plot(PC_range, variance_V, 'b', marker = 'x')\n",
    "    ax1.set_xlabel('PC')\n",
    "    ax1.set_ylabel('PC variance', color='b')\n",
    "    ax1.set_ylim(0,variance_V.max()*1.1)\n",
    "    plt.xticks(np.linspace(PC_range.min(),PC_range.max(),len(PC_range)))\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(PC_range, np.cumsum(explained_variance_ratio)*100, 'r', marker = 'x')\n",
    "    ax2.set_ylabel('Ratio of explained variance (%)', color='r')\n",
    "    ax2.set_ylim(0,105)\n",
    "    \n",
    "    plt.xlim(PC_range.min() - 0.1,PC_range.max() + 0.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbc58d-f8e9-4abd-bd49-0b537e8aae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Visualize the Error matrix, when X is \n",
    "# projected onto selected principal components\n",
    "# if p is undefined, X is only projected to tensor product\n",
    "# of PC1, the first principal component\n",
    "# ==================================================\n",
    "\n",
    "def error_heatmap(X_,V_,p = 1):\n",
    "    \n",
    "    X_ = X_.to_numpy()\n",
    "    X_reprod = X_*0\n",
    "    \n",
    "    for i in range(p):\n",
    "        \n",
    "        PC_i = V_[:,i].reshape((-1,1))\n",
    "\n",
    "        X_reprod_i = X_@PC_i@PC_i.T\n",
    "        X_reprod = X_reprod + X_reprod_i\n",
    "    \n",
    "    # calculate error\n",
    "    E = X_ - X_reprod\n",
    "    \n",
    "    print(X_reprod)\n",
    "\n",
    "    fig,axs = plt.subplots(1,5,figsize = (16,6))\n",
    "\n",
    "    X_max = np.max(X_)\n",
    "    X_min = np.min(X_)\n",
    "    \n",
    "    plt.sca(axs[0])\n",
    "    ax = sns.heatmap(E, cmap = 'RdYlBu_r',\n",
    "                    vmax = X_max, vmin = X_min,\n",
    "                    cbar_kws = {'orientation':'horizontal'},\n",
    "                    yticklabels=False)\n",
    "    plt.title('Error, $E$')\n",
    "    \n",
    "    plt.sca(axs[1])\n",
    "    plt.title('=')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.sca(axs[2])\n",
    "    ax = sns.heatmap(X_, cmap = 'RdYlBu_r',\n",
    "                    vmax = X_max, vmin = X_min,\n",
    "                    cbar_kws = {'orientation':'horizontal'},\n",
    "                    yticklabels=False)\n",
    "    plt.title('Original, $X$')\n",
    "    \n",
    "    plt.sca(axs[3])\n",
    "    plt.title('-')\n",
    "    plt.axis('off')    \n",
    "    \n",
    "    plt.sca(axs[4])\n",
    "    ax = sns.heatmap(X_reprod, cmap = 'RdYlBu_r',\n",
    "                    vmax = X_max, vmin = X_min,\n",
    "                    cbar_kws = {'orientation':'horizontal'},\n",
    "                    yticklabels=False)\n",
    "    plt.title('Reproduced, $\\hat{X}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8bdb7d-28df-47eb-9739-20ff5ea35161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_heatmap(X_,V_):\n",
    "    \n",
    "    X_ = X_.to_numpy()\n",
    "    Y = X_@V_\n",
    "\n",
    "    fig,axs = plt.subplots(1,5,figsize = (16,6))\n",
    "\n",
    "    X_max = np.max(X_)\n",
    "    X_min = np.min(X_)\n",
    "    \n",
    "    plt.sca(axs[0])\n",
    "    ax = sns.heatmap(Y, cmap = 'RdYlBu_r',\n",
    "                    vmax = X_max, vmin = X_min,\n",
    "                    cbar_kws = {'orientation':'horizontal'},\n",
    "                    yticklabels=False)\n",
    "    plt.title('$Y$')\n",
    "    \n",
    "    plt.sca(axs[1])\n",
    "    plt.title('=')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.sca(axs[2])\n",
    "    ax = sns.heatmap(X_, cmap = 'RdYlBu_r',\n",
    "                    vmax = X_max, vmin = X_min,\n",
    "                    cbar_kws = {'orientation':'horizontal'},\n",
    "                    yticklabels=False)\n",
    "    plt.title('$X$')\n",
    "    \n",
    "    plt.sca(axs[3])\n",
    "    plt.title('@')\n",
    "    plt.axis('off')    \n",
    "    \n",
    "    plt.sca(axs[4])\n",
    "    ax = sns.heatmap(V_, cmap = 'RdYlBu_r',\n",
    "                    vmax = 1, vmin = -1,\n",
    "                    cbar_kws = {'orientation':'horizontal'},\n",
    "                    yticklabels=False,square = 'equal')\n",
    "    plt.title('$V$')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c6012-649f-4e90-8272-2bd4ff89aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "#%% import dataset of iris data from seaborn\n",
    "\n",
    "X = sns.load_dataset(\"iris\")\n",
    "X = X.drop(columns=['species'])\n",
    "\n",
    "# X = X.rename(columns={'sepal_length': 'Sepal length',\n",
    "#                       'sepal_width':  'Sepal width',\n",
    "#                       'petal_length': 'Petal length',\n",
    "#                       'petal_width':  'Petal width'})\n",
    "\n",
    "# rename column headers\n",
    "X = X.rename(columns={'sepal_length': '$X_1$',\n",
    "                      'sepal_width':  '$X_2$',\n",
    "                      'petal_length': '$X_3$',\n",
    "                      'petal_width':  '$X_4$'})\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea1d954-eaa8-496d-b99d-d59546e1ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Perform PCA on the demeaned data\n",
    "# by eigen decomposing covariance matrix\n",
    "# ==================================================\n",
    "\n",
    "explained_variance_ratio_c, variance_V_c, V_c, original_variance_c, GG_c, X_c = PCA(X, method = 'demean')\n",
    "\n",
    "# heatmap of EVD\n",
    "heatmap_EVD(GG_c,variance_V_c,V_c)\n",
    "\n",
    "\n",
    "# heatmap of before and after eigen decomposition\n",
    "\n",
    "heatmap_GG(GG_c, variance_V_c)\n",
    "\n",
    "bar_max = np.maximum(original_variance_c, variance_V_c).max().max()\n",
    "pie_and_barh(original_variance_c,bar_max,PCA = False)\n",
    "pie_and_barh(variance_V_c,bar_max,PCA = True)\n",
    "\n",
    "cov_X = X.cov()\n",
    "sum_variance = np.diag(cov_X).sum() # test only\n",
    "\n",
    "# The diagonal elements of covariance matrix are variances; thus each feature contributes its real variance in PCA.\n",
    "# Scree plot\n",
    "\n",
    "Scree(explained_variance_ratio_c, variance_V_c)\n",
    "\n",
    "heatmap_V(V_c,X,'V from eigen decomposing covariance matrix $\\Sigma$')\n",
    "\n",
    "# biplot of the coefficients in PC1 (v1) and PC2 (v2)\n",
    "\n",
    "biplot(V_c,X,'Biplot of $PC_1$ and $PC_2$, covariance matrix $\\Sigma$')\n",
    "\n",
    "# Note: the center of the vectors ideally should be at the centroid of the data matrix X\n",
    "\n",
    "# six biplots in lower triangle\n",
    "\n",
    "six_biplots(V_c,X)\n",
    "\n",
    "# Reproduce X_c using PC1 from V_c only and plot error heatmap\n",
    "\n",
    "# X_c_ = X - X.mean() # for test only\n",
    "error_heatmap(X_c, V_c, 1)\n",
    "\n",
    "\n",
    "# projection Y_c = X_c @ V_c\n",
    "# Y_c = X_c @ V_c\n",
    "projection_heatmap(X_c,V_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ab146-8303-417b-863c-10be43a6d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# ==================================================\n",
    "# Perform PCA on the original data\n",
    "# by eigen decomposing Gram matrix G = X.T@X\n",
    "# ==================================================\n",
    "\n",
    "explained_variance_ratio, variance_V, V, original_variance, GG, X_ = PCA(X, method = 'original')\n",
    "\n",
    "# heatmap of EVD\n",
    "heatmap_EVD(GG,variance_V,V)\n",
    "\n",
    "# heatmap of before and after eigen decomposition\n",
    "\n",
    "heatmap_GG(GG, variance_V)\n",
    "\n",
    "# Note: results in variance_V are L2 norm squared devided by (n-1), not variances\n",
    "\n",
    "# pie and bar charts\n",
    "\n",
    "bar_max = np.maximum(original_variance, variance_V).max().max()\n",
    "\n",
    "pie_and_barh(original_variance, bar_max, PCA = False)\n",
    "pie_and_barh(variance_V, bar_max,PCA = True)\n",
    "\n",
    "# Scree plot\n",
    "\n",
    "Scree(explained_variance_ratio,variance_V)\n",
    "\n",
    "# Heatmap of V\n",
    "\n",
    "heatmap_V(V,X,'V from eigen decomposing Gram matrix G')\n",
    "\n",
    "# biplot of the coefficients in PC1 (v1) and PC2 (v2)\n",
    "\n",
    "biplot(V,X,'Biplot of $PC_1$ and $PC_2$, Gram matrix G')\n",
    "\n",
    "\n",
    "# six biplots in lower triangle\n",
    "\n",
    "six_biplots(V,X)\n",
    "\n",
    "# reproduction\n",
    "\n",
    "# Reproduce the original data using PC1 from V only and plot error heatmap\n",
    "\n",
    "error_heatmap(X, V, 1)\n",
    "\n",
    "# projection Y = X @ V\n",
    "# Y = X @ V\n",
    "# Y_c_2 = X @ V_c\n",
    "projection_heatmap(X,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d0d5bb-163c-47df-816d-5f2b9e9acd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# ==================================================\n",
    "# Perform PCA on the normalized (or standardized) data, i.e., z-scores\n",
    "# by eigen decomposing correlation matrix\n",
    "# ==================================================\n",
    "\n",
    "explained_variance_ratio_z, variance_V_z, V_z,original_variance_z, GG_z, Z  = PCA(X, method = 'normalize')\n",
    "\n",
    "# heatmap of EVD\n",
    "heatmap_EVD(GG_z,variance_V_z,V_z)\n",
    "\n",
    "# heatmap of before and after eigen decomposition\n",
    "\n",
    "heatmap_GG(GG_z, variance_V_z)\n",
    "\n",
    "# The diagonal elements of correlation matrix are all 1; thus each feature only contribute 1 as variance in PCA.\n",
    "bar_max = np.maximum(original_variance_z, variance_V_z).max().max()\n",
    "pie_and_barh(original_variance_z,bar_max,PCA = False)\n",
    "pie_and_barh(variance_V_z,bar_max,PCA = True)\n",
    "\n",
    "variance_V_z.sum()\n",
    "\n",
    "Scree(explained_variance_ratio_z, variance_V_z)\n",
    "\n",
    "heatmap_V(V_z,X,'V from eigen decomposing correlation matrix $P$')\n",
    "\n",
    "# biplot of the coefficients in PC1 (v1) and PC2 (v2)\n",
    "\n",
    "biplot(V_z,X,'Biplot of $PC_1$ and $PC_2$, correlation matrix $P$')\n",
    "\n",
    "# six biplots in lower triangle\n",
    "\n",
    "six_biplots(V_z,X)\n",
    "\n",
    "# Reproduce the original data using PC1 from V_z only and plot error heatmap\n",
    "\n",
    "error_heatmap(Z, V_z, 1)\n",
    "\n",
    "# projection Y_z = Z @ V_z\n",
    "\n",
    "projection_heatmap(Z,V_z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
